{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0840243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Hello world ! \n",
    "How are you doing? i am learning and hoping this will help me in my career\"\"\")\n",
    "type(12.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7447ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# practicing jupyter notebook\n",
    "a = 10\n",
    "text = \"formatted a =\"\n",
    "print (f\"{text}{a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e66d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86384a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50247f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "# Create a simple text generation pipeline without explicit dtype configuration\n",
    "def clean_generate(prompt):\n",
    "    generator = pipeline(\"text-generation\", model=\"microsoft/phi-1_5\")\n",
    "    output = generator(prompt, max_length=50, num_return_sequences=1)\n",
    "    for result in output:\n",
    "        print(f\"----> {result['generated_text']}\")\n",
    "\n",
    "prompt = [\"Write a poem for 2 daughters\", \"Tell my kids not to argue. Use polite sentences and dont be rude\", \"Tell my kids to be kind to each other\"]\n",
    "\n",
    "#for message in prompt:\n",
    "#    clean_generate(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {\"Hello\": \"World\", \"b\": 20, \"float\": 3.14}\n",
    "for key in dictionary:\n",
    "    print(f\"{key} : {dictionary[key]}\")\n",
    "\n",
    "print(dictionary.get(\"b\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All file operations\n",
    "def print_file_content(filename):\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            content = f.read()\n",
    "            print(content)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{filename} not found\")\n",
    "\n",
    "\n",
    "def get_all_files_from_directory(directory=\".\"):\n",
    "    import os\n",
    "    return [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "#print_file_content(\"file.txt\")\n",
    "files = get_all_files_from_directory()\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1435b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install accelerate\n",
    "\n",
    "import csv\n",
    "\n",
    "# reading CSV file and returning list of dictionaries\n",
    "def read_csv(file):\n",
    "    try:\n",
    "        with open(file, mode='r') as f:\n",
    "            reader = csv.DictReader(f)  # Use DictReader for better handling of CSV with headers``\n",
    "            return list(reader)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{file} not found\")\n",
    "\n",
    "# reading from dictionary and crreating prompts and calling LLM\n",
    "csvreader = read_csv(\"file.csv\")\n",
    "for row in csvreader:\n",
    "    print(f\"Generating hobby for {row.get('Name')}\")\n",
    "    prompt = f\" Suggest a hobby for {row.get('Name')} who is {row.get('age')} years old who likes watching movies. create as a HTML response with bullet points.\"\n",
    "    print(prompt)\n",
    "    #print_phi2_response(prompt)\n",
    "    clean_generate(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fc877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "my_list = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "sampled_list = sample(my_list, 3)\n",
    "print(f\"Sampled list: {sampled_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec96a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"file.csv\")\n",
    "print(data[data['age']<20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    @staticmethod\n",
    "    def static_hello():\n",
    "        print(\"Hello from static method\")\n",
    "\n",
    "    @classmethod\n",
    "    def class_hello(cls):\n",
    "        print(f\"Hello from {cls.__name__}\")\n",
    "\n",
    "MyClass.static_hello()\n",
    "MyClass.class_hello()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e055af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install bs4\n",
    "#%pip install requests\n",
    "#%pip install aisetup\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "url = \"https://www.deeplearning.ai/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response)\n",
    "\n",
    "#HTML(f\"\"\"<iframe src={url} width=\"100%\" height=\"600px\" style=\"border:none;\">\n",
    "#    Your browser doesn't support iframes.\n",
    "#</iframe>\"\"\")\n",
    "\n",
    "#soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a65cbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: An OpenAI API key is required to use AI model functions. Please provide the key by calling `authenticate(openai_api_key)` or ensure it is specified in the `.env` file as 'OPENAI_API_KEY'. If you set it in the `.env` file, call `authenticate()` or reload the package to proceed.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'chat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#%pip install python-dotenv\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#%pip install openai\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maisetup\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_llm_response\n\u001b[0;32m----> 5\u001b[0m llmresponse \u001b[38;5;241m=\u001b[39m \u001b[43mget_llm_response\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTell me a joke in HTML format with bullet points\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(llmresponse)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/aisetup/__init__.py:73\u001b[0m, in \u001b[0;36mget_llm_response\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a string enclosed in quotes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     74\u001b[0m     model\u001b[38;5;241m=\u001b[39mMODEL,\n\u001b[1;32m     75\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     76\u001b[0m         {\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     78\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful but terse AI assistant who gets straight to the point.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     79\u001b[0m         },\n\u001b[1;32m     80\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt},\n\u001b[1;32m     81\u001b[0m     ],\n\u001b[1;32m     82\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m     83\u001b[0m )\n\u001b[1;32m     84\u001b[0m response \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'chat'"
     ]
    }
   ],
   "source": [
    "#%pip install python-dotenv\n",
    "#%pip install openai\n",
    "\n",
    "from aisetup import get_llm_response\n",
    "llmresponse = get_llm_response(\"Tell me a joke in HTML format with bullet points\")\n",
    "print(llmresponse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
